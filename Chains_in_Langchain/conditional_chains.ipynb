{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a555d99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dear Customer,\n",
      "\n",
      "We are sorry to hear that you had a negative experience. Your satisfaction is our top priority, and we want to ensure that we are meeting and exceeding your expectations. We appreciate your feedback and would like to make things right. Please contact us so we can discuss your concerns and find a solution.\n",
      "\n",
      "Thank you for bringing this to our attention.\n",
      "\n",
      "Best Regards,\n",
      "[Your Company Name]\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel, RunnableBranch, RunnableLambda\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "llm1 = HuggingFaceEndpoint(\n",
    "    repo_id = repo_id,\n",
    "    task = \"text-generation\", \n",
    "    huggingfacehub_api_token=os.getenv(\"HUGGINGFACEHUB_ACCESS_TOKEN\")\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm1)\n",
    "\n",
    "\n",
    "\n",
    "parser1 = StrOutputParser()\n",
    "\n",
    "\n",
    "class Feedback(BaseModel):\n",
    "\n",
    "    sentiment : Literal[\"positive\", \"negative\"] = Field(description=\"give the sentiment of the feedback\")\n",
    "\n",
    "parser2 = PydanticOutputParser(pydantic_object=Feedback)\n",
    "\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    template=\"classity the sentiment of the following feedback text into positive or negative \\n {feedback} \\n {format_instruction}\",\n",
    "    input_variables=[\"feedback\"],\n",
    "    partial_variables={\"format_instruction\": parser2.get_format_instructions()}\n",
    ")\n",
    "\n",
    "\n",
    "classifier_chain = prompt1 | model | parser2\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template=\"write an appropriate response to this positive feedback \\n {feedback}\",\n",
    "    input_variables=[\"Feedback\"]\n",
    ")\n",
    "\n",
    "prompt3 = PromptTemplate(\n",
    "    template=\"write an appropriate response to this negative feedback \\n {feedback}\",\n",
    "    input_variables=[\"Feedback\"]\n",
    ")\n",
    "\n",
    "branch_chain = RunnableBranch(\n",
    "    (lambda x : x.sentiment == \"positive\", prompt2 | model | parser1),\n",
    "    (lambda x : x.sentiment == \"negative\", prompt3 | model | parser1),\n",
    "    RunnableLambda(lambda x : \"could not find sentiment\")\n",
    ")\n",
    "\n",
    "\n",
    "chain = classifier_chain | branch_chain\n",
    "\n",
    "result = chain.invoke({\"feedback\" : \"This product was terrible! It broke after only one use and customer service was unhelpful.\"})\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f36568cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-------------+      \n",
      "    | PromptInput |      \n",
      "    +-------------+      \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "   +----------------+    \n",
      "   | PromptTemplate |    \n",
      "   +----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "  +-----------------+    \n",
      "  | ChatHuggingFace |    \n",
      "  +-----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+----------------------+ \n",
      "| PydanticOutputParser | \n",
      "+----------------------+ \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "       +--------+        \n",
      "       | Branch |        \n",
      "       +--------+        \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "    +--------------+     \n",
      "    | BranchOutput |     \n",
      "    +--------------+     \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cfe471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
