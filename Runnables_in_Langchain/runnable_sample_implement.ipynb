{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "93b31dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Runnable(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def invoke(self, input_data):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f3cf22d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class nakliLLM(Runnable): \n",
    "\n",
    "    def __init__(self):\n",
    "        print(\"llm created\")\n",
    "\n",
    "    def invoke(self, input_data):\n",
    "        response_lst = [\n",
    "            \"I'm not sure I understand what you're asking.\",\n",
    "            \"I'm not sure I can help with that.\",\n",
    "            \"I'm not sure I can provide a helpful response.\",\n",
    "        ]\n",
    "\n",
    "        return {\"response\" : random.choice(response_lst)}\n",
    "\n",
    "    def predict(self, prompt):\n",
    "\n",
    "        response_lst = [\n",
    "            \"I'm not sure I understand what you're asking.\",\n",
    "            \"I'm not sure I can help with that.\",\n",
    "            \"I'm not sure I can provide a helpful response.\",\n",
    "        ]\n",
    "\n",
    "        print(\"this method is going to deprecte in the future please use invoke method instead\")\n",
    "        return {\"response\" : random.choice(response_lst)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "cf092a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm created\n"
     ]
    }
   ],
   "source": [
    "llm = nakliLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "c51e9d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this method is going to deprecte in the future please use invoke method instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': \"I'm not sure I understand what you're asking.\"}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"what is the capital of india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "fe4c0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nakliPromptTemplate(Runnable):\n",
    "\n",
    "    def __init__(self, template, input_variables):\n",
    "        self.template = template\n",
    "        self.input_variables = input_variables\n",
    "\n",
    "\n",
    "    def invoke(self, input_dict):\n",
    "        for var in self.input_variables:\n",
    "            if var not in input_dict:\n",
    "                raise ValueError(f\"Missing input variable: {var}\")\n",
    "            \n",
    "        for key in input_dict.keys():\n",
    "            if key not in self.input_variables:\n",
    "                raise ValueError(f\"Unknown input variable: {key}\")\n",
    "        return self.template.format(**input_dict)\n",
    "\n",
    "\n",
    "    def Format(self, input_dict):\n",
    "        for var in self.input_variables:\n",
    "            if var not in input_dict:\n",
    "                raise ValueError(f\"Missing input variable: {var}\")\n",
    "            \n",
    "        for key in input_dict.keys():\n",
    "            if key not in self.input_variables:\n",
    "                raise ValueError(f\"Unknown input variable: {key}\")\n",
    "        \n",
    "        print(\"this method is going to be deprecated in the future please use invoke() method instead\")\n",
    "        return self.template.format(**input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "31499806",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = nakliPromptTemplate(\n",
    "    template=\"explain the {topic} in detail\",\n",
    "    input_variables=[\"topic\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "dbe72480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explain the cricket in detail'"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.invoke({\"topic\" : \"cricket\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a3f79aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nakliStrOutputParser(Runnable):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def invoke(self, input_data):\n",
    "        return input_data[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6ee72207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunnableConnector(Runnable):\n",
    "\n",
    "    def __init__(self, runnable_list):\n",
    "        self.runnable_list = runnable_list\n",
    "\n",
    "\n",
    "    def invoke(self, input_data):\n",
    "        for runnable in self.runnable_list:\n",
    "            input_data = runnable.invoke(input_data)\n",
    "\n",
    "        return input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "cdb52e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = nakliPromptTemplate(\n",
    "    template=\"explain the {topic} in detail\",\n",
    "    input_variables=[\"topic\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "b53c62f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm created\n"
     ]
    }
   ],
   "source": [
    "llm = nakliLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "3fe6a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nakliStrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "17a3b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableConnector([template, llm, parser])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "1f6d177a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm not sure I can help with that.\""
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"india\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6158e0",
   "metadata": {},
   "source": [
    "now we combine the chains to form bigger chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "cd5b6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = nakliPromptTemplate(\n",
    "    template= \"write a joke about the {topic}\",\n",
    "    input_variables= [\"topic\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "876a1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "template2 = nakliPromptTemplate(\n",
    "    template= \"explain the following joke {response}\",\n",
    "    input_variables= [\"response\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "88d0031c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm created\n"
     ]
    }
   ],
   "source": [
    "llm = nakliLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "c4d748ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nakliStrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ce5d3d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = RunnableConnector([template1, llm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c158d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2 = RunnableConnector([template2, llm, parser])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "197ef632",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = RunnableConnector([chain1, chain2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "8827fb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm not sure I understand what you're asking.\""
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke({\"topic\" : \"cricket\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80725aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
