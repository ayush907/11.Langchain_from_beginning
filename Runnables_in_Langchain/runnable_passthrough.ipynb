{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e2219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dheka\\OneDrive\\Desktop\\11.Langchain_from_beginning\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'football'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableSequence, RunnablePassthrough, RunnableParallel\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=os.getenv(\"HUGGIGNFACEHUB_API_TOKEN\")\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm = llm)\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "passthrough = RunnablePassthrough()\n",
    "\n",
    "print(passthrough.invoke({\"topic\" : \"football\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb5225d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': ' Why don\\'t grasshoppers watch football?\\n\\nThey prefer cricket!\\n\\nExplanation: This joke is a play on words, as \"football\" and \"cricket\" are two different sports, but \"grasshoppers\" can also refer to actual insects that might prefer watching other insects (like crickets) instead of a football game.', 'explaination': ' The joke is playing with the double meaning of the word \"cricket.\" On one hand, \"cricket\" is a type of insect that a grasshopper might watch out of interest. On the other hand, \"cricket\" is also a sport that is an alternative to football (soccer) for the grasshopper to watch. The joke is implied that grasshoppers don\\'t watch football because they prefer watching their own kind of cricket.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableSequence, RunnablePassthrough, RunnableParallel\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=os.getenv(\"HUGGIGNFACEHUB_API_TOKEN\")\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm = llm)\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "passthrough = RunnablePassthrough()\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    template=\"write the joke about the {topic}\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template= \"explain the folowing joke {text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "sequence_chain = RunnableSequence(prompt1, model, parser)\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"joke\" : RunnablePassthrough(),\n",
    "    \"explaination\" : RunnableSequence(prompt2, model, parser)\n",
    "})\n",
    "\n",
    "final_chain = RunnableSequence(sequence_chain, parallel_chain)\n",
    "\n",
    "result = final_chain.invoke({\"topic\" : \"football\"})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fc777cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   +-------------+                   \n",
      "                   | PromptInput |                   \n",
      "                   +-------------+                   \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "                  +----------------+                 \n",
      "                  | PromptTemplate |                 \n",
      "                  +----------------+                 \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "                 +-----------------+                 \n",
      "                 | ChatHuggingFace |                 \n",
      "                 +-----------------+                 \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "                 +-----------------+                 \n",
      "                 | StrOutputParser |                 \n",
      "                 +-----------------+                 \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "        +----------------------------------+         \n",
      "        | Parallel<joke,explaination>Input |         \n",
      "        +----------------------------------+         \n",
      "                 ***              ***                \n",
      "              ***                    ***             \n",
      "            **                          ***          \n",
      "+----------------+                         **        \n",
      "| PromptTemplate |                          *        \n",
      "+----------------+                          *        \n",
      "          *                                 *        \n",
      "          *                                 *        \n",
      "          *                                 *        \n",
      "+-----------------+                         *        \n",
      "| ChatHuggingFace |                         *        \n",
      "+-----------------+                         *        \n",
      "          *                                 *        \n",
      "          *                                 *        \n",
      "          *                                 *        \n",
      "+-----------------+                 +-------------+  \n",
      "| StrOutputParser |                 | Passthrough |  \n",
      "+-----------------+                 +-------------+  \n",
      "                 ***              ***                \n",
      "                    ***        ***                   \n",
      "                       **    **                      \n",
      "        +-----------------------------------+        \n",
      "        | Parallel<joke,explaination>Output |        \n",
      "        +-----------------------------------+        \n"
     ]
    }
   ],
   "source": [
    "final_chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a5f074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
